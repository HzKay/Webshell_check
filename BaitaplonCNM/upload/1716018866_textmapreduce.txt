Bước 1: copy file lên máy ảo
strat-all.sh
B2: Tạo thư mục mycode

mkdir mycode

Di chuyển file mapper.py reducer.py vào mycode

mv mapper.py mycode
mv reducer.py mycode

Tiến hành phân quyền 777 cho mapper.py reducer.py
sudo chmod 777 mycode/mapper.py
sudo chmod 777 mycode/reducer.py
ls -l mycode

Tạo thư mục mydata trên hdfs
hdfs dfs -mkdir /mydata
Di chuyển file data vào thư mục data
hdfs dfs -copyFromLocal /home/hduser/data.csv /mydata
hdfs dfs -ls /mydata

Tạo thư mục lưu kết quả
hdfs dfs -mkdir /myresult
hdfs dfs -ls /
cd $HADOOP_HOME

ls -l share/hadoop/tools/lib/ | grep stream
hdfs dfs -ls /mydata

hdfs dfs -copyFromLocal /home/hduser/01/emp_data.csv /mydata

hadoop jar share/hadoop/tools/lib/hadoop-streaming-2.6.5.jar -files "/home/hduser/mycode/mapper.py,/home/hduser/mycode/reducer.py" -mapper "python mapper.py" -reducer "python reducer.py" -input /mydata/* -output /myresult/out-res01

hdfs dfs -ls /myresult/minsalary

hdfs dfs -cat  /myresult/minsalary/part-00000

Chạy pig

copy file data
hdfs dfs -copyFromLocal /home/hduser/data.csv ‘hdfs://localhost:54310/tenthumucchuyen/
pig
grunt>loadbookdata = LOAD 'hdfs://localhost:54310/XinChaoCacBan/bookdata.csv' USING org.apache.pig.piggybank.storage.CSVExcelStorage() as (bookbookname:chararray,cost:chararray,stock:chararray,description:chararray,rating:chararray);

grunt>STORE loadbookdata INTO ' hdfs://localhost:54310/book_Output/ ' USING org.apache.pig.piggybank.storage.CSVExcelStorage();
Mô tả
grunt>describe loadbookdata;
Toán tử
grunt>Dump loadbookdata
Giải thích

grunt>explain Relation_name;

Toán tử minh họa
grunt> illustrate Relation_name;

toán tử nhóm
grunt> Group_data = GROUP Relation_name BY age;
grunt> Dump group_data;
grunt> Describe group_data;
Nhóm nhiều cột
grunt> group_multiple = GROUP student_details by (age, city);
Nhóm tất cả
grunt> group_all = GROUP student_details All;